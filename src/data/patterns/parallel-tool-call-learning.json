{
  "id": "parallel-tool-call-learning",
  "title": "Parallel Tool Call Learning",
  "title_ko": "병렬 도구 호출 학습",
  "category": "Orchestration & Control",
  "status": "emerging",
  "original_url": "https://youtu.be/1s_7RMG4O4U",
  "problem": {
    "en": "Agents execute tool calls sequentially even when they could run in parallel, causing unnecessary latency. Base models may not naturally parallelize without training signal.",
    "ko": "에이전트가 병렬로 실행할 수 있는 경우에도 도구 호출을 순차적으로 실행하여 불필요한 지연을 유발합니다. 기본 모델은 훈련 신호 없이 자연스럽게 병렬화하지 않을 수 있습니다."
  },
  "solution": {
    "en": "Use Agent RFT to teach the model to parallelize independent tool calls. The model discovers through RL exploration that parallel patterns receive similar rewards in less time.",
    "ko": "Agent RFT를 사용하여 모델이 독립적인 도구 호출을 병렬화하도록 가르칩니다. 모델은 RL 탐색을 통해 병렬 패턴이 더 짧은 시간에 유사한 보상을 받는다는 것을 발견합니다."
  },
  "ascii_diagram": "BEFORE (Sequential):\n1. search(A) → 2s\n2. search(B) → 2s\n3. read(X)   → 1.5s\n4. read(Y)   → 1.5s\nTotal: 7s\n\nAFTER (Learned Parallel):\nBatch 1 (parallel):\n  search(A) ┐\n  search(B) ├→ 2s\n  read(X)   ┘\nBatch 2:\n  read(Y)   → 1.5s\nTotal: 3.5s (50% faster)",
  "mermaid_diagram": "graph TD\n    A[Agent Receives Task] --> B{RL-Trained Model}\n    B --> C[Identifies Independent Queries]\n    C --> D[Batch 1: Parallel Tool Calls]\n    D --> E[All Tools Execute Concurrently]\n    E --> F[Results Arrive Together]\n    F --> G{Need More Info?}\n    G -->|Yes| H[Batch 2: Parallel Calls]\n    G -->|No| I[Generate Answer]\n    H --> I",
  "code_example": "# Parallelization emerges from RL training\n# No special flag needed - model discovers this pattern\n\njob = client.fine_tuning.jobs.create(\n    training_file='file-abc123',\n    model='gpt-4o',\n    method='rft',\n    rft={\n        'tools': tools,\n        'grader': grader,\n        'hyperparameters': {\n            'n_epochs': 3,\n            'batch_size': 16,\n            'compute_multiplier': 1\n        }\n    }\n)\n\n# Result: Model learns to batch independent tool calls\n# Baseline: 8 sequential calls\n# Fine-tuned: 2 parallel batches (50% latency reduction)",
  "when_to_use": {
    "en": ["Tool execution faster than inference", "Independent information gathering", "Broad exploration phases"],
    "ko": ["도구 실행이 추론보다 빠를 때", "독립적인 정보 수집", "광범위한 탐색 단계"]
  },
  "pros": {
    "en": ["40-50% latency reduction", "Emerges naturally from training", "Adapts to specific tools"],
    "ko": ["40-50% 지연 감소", "훈련에서 자연스럽게 발현", "특정 도구에 적응"]
  },
  "cons": {
    "en": ["Infrastructure must support concurrent requests", "Higher peak resource usage", "Debugging complexity"],
    "ko": ["인프라가 동시 요청 지원해야 함", "높은 피크 자원 사용", "디버깅 복잡성"]
  },
  "tags": ["parallelization", "latency-optimization", "tool-use", "reinforcement-learning", "performance"]
}
