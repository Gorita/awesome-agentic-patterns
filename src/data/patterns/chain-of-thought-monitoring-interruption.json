{
  "id": "chain-of-thought-monitoring-interruption",
  "title": "Chain-of-Thought Monitoring & Interruption",
  "title_ko": "사고 사슬 모니터링 및 중단",
  "category": "UX & Collaboration",
  "status": "emerging",
  "original_url": "https://claude.com/blog/building-companies-with-claude-code",
  "problem": {
    "en": "AI agents can pursue misguided reasoning paths for extended periods before producing outputs. By the time developers realize the approach is wrong, significant time and tokens have been wasted. Traditional 'fire and forget' execution provides no opportunity for early correction.",
    "ko": "AI 에이전트는 출력을 생성하기 전에 오랜 기간 동안 잘못된 추론 경로를 추구할 수 있습니다. 개발자가 접근 방식이 잘못되었음을 깨달을 때쯤이면 상당한 시간과 토큰이 낭비됩니다. 전통적인 '실행 후 잊기' 방식은 조기 수정 기회를 제공하지 않습니다."
  },
  "solution": {
    "en": "Implement active surveillance of agent's intermediate reasoning with capability to interrupt and redirect. Monitor chain-of-thought outputs, tool calls, and intermediate results in real-time, maintaining a 'finger on the trigger' to catch wrong directions early.",
    "ko": "에이전트의 중간 추론에 대한 적극적인 감시를 구현하고 중단 및 재지향 기능을 제공합니다. 사고 사슬 출력, 도구 호출, 중간 결과를 실시간으로 모니터링하며, 잘못된 방향을 조기에 잡기 위해 '방아쇠에 손가락'을 유지합니다."
  },
  "ascii_diagram": "┌─────────────────────────────────┐\n│         Developer               │\n│   Watching Agent Reasoning      │\n└───────────────┬─────────────────┘\n                │ Monitor\n┌───────────────▼─────────────────┐\n│   Agent: \"I'll modify auth.ts\"  │\n│   Agent: Start file read...     │\n└───────────────┬─────────────────┘\n                │\n        ┌───────▼───────┐\n        │ INTERRUPT!    │\n        │ (Wrong file)  │\n        └───────┬───────┘\n                │\n┌───────────────▼─────────────────┐\n│   Dev: \"Use oauth.ts instead\"   │\n└───────────────┬─────────────────┘\n                │\n┌───────────────▼─────────────────┐\n│   Agent: Read oauth.ts          │\n│   Agent: Updated reasoning...   │\n└─────────────────────────────────┘\n\n  Correction caught in first tool call!",
  "mermaid_diagram": "sequenceDiagram\n    participant Dev as Developer\n    participant Agent as AI Agent\n    participant Tools as Tool Execution\n    Agent->>Dev: Display reasoning: \"I'll modify auth.ts...\"\n    Agent->>Tools: Start file read\n    Dev->>Agent: INTERRUPT! (Wrong file)\n    Dev->>Agent: \"Use oauth.ts instead\"\n    Agent->>Tools: Read oauth.ts\n    Agent->>Dev: Display updated reasoning\n    Note over Dev,Agent: Correction caught within<br/>first tool call",
  "code_example": "# Real-time reasoning visibility\nclass MonitoredAgent:\n    async def execute_with_monitoring(self, task):\n        async for step in self.stream_reasoning(task):\n            # Show each step to user in real-time\n            display_to_user(step)\n            \n            # Check for interrupt signal\n            if user_interrupted():\n                correction = get_user_input()\n                # Inject correction into context\n                self.inject_context(correction)\n                continue\n            \n            # Execute step\n            await self.execute_step(step)\n\n# UI implementation: Ctrl+C to interrupt with context preservation\n# CLI: Stream verbose output, allow redirect with additional context",
  "when_to_use": {
    "en": ["Complex refactoring tasks", "High-stakes operations (migrations, API changes)", "Ambiguous requirements", "Tasks requiring deep codebase understanding"],
    "ko": ["복잡한 리팩토링 작업", "고위험 작업 (마이그레이션, API 변경)", "모호한 요구사항", "깊은 코드베이스 이해가 필요한 작업"]
  },
  "pros": {
    "en": ["Prevents wasted time on wrong approaches", "Maximizes value from expensive model calls", "Enables collaborative human-AI problem solving", "Catches misunderstandings early"],
    "ko": ["잘못된 접근에 대한 시간 낭비 방지", "비싼 모델 호출에서 가치 극대화", "협력적 인간-AI 문제 해결 가능", "오해를 조기에 포착"]
  },
  "cons": {
    "en": ["Requires active human attention", "May interrupt productive exploration", "Adds cognitive load to monitor", "Risk of over-correcting valid approaches"],
    "ko": ["적극적인 인간 주의 필요", "생산적인 탐색을 중단할 수 있음", "모니터링에 인지 부하 추가", "유효한 접근을 과도하게 수정할 위험"]
  },
  "tags": ["monitoring", "intervention", "debugging", "reasoning", "ux", "human-in-loop"]
}
